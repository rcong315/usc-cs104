2) [24, 22, 20, 18, 16, 14, 12, 10, 8, 6, 4, 2] would achieve the worst-possible pivot selection over all calls to partition.
Every iteration of partition finds the median of the beginning, middle, and end values, swaps it with the end, and makes it the pivot. Then the algorithm compares each element to the pivot, swapping the element with i and incrementing i if the element is less than the pivot. If we use an array that is reversed, every time the pivot will be close to the median of all the values because the pivot is chosen from the middle. After one call of partition on the array above and assuming L is 0 and R is 11, it will be changed to 
[12, 10, 8, 6, 4, 2, 14, 20, 18, 16, 24, 22]
The next pivot will be chosen by picking the median from 12, 2, and 22, which is 12. But because everything less than 12 is already at the left, another call to partition will do nothing except swap 12 and 14. Then the new pivot is 14 and everything less than 14 is already to the left. This keeps on going until the array is sorted. This is very unefficient because each additional call to partition will sort only a few elements of the array, leading to the worst case run time.

4c) If k is larger than n, then I use selection sort to sort the vector which will take theta(n^2). But otherwise, the algorithm will use the implemented k-way merge sort. For an input size n and the number of splits k, the recurence relation is f(n, k) = k * f(n / k, k) + c(k + n). K will either be less than or equal to n, so we can simplify the relation to f(n, k) = k * f(n / k, k) + cn. For each recursive call to merge sort, the vector size is divided by k so the run time for each is log base k. The total amount of calls however will be n * k, because the merge sort function splits the vector size n until each partition is size 1 (or less than k) and each time it splits, k merge sorts will be recursively called. Therefore the runtime for the whole merge sort algorithm will be theta(knlogn).